{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ hitting all question in dataset ____ \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to 'dataset' dataframe add empty columns for agents intermediate steps and the agents answer. also add a column called gpt-4 answer.\n",
    "dataset['agent_intermediate_steps'] = ''\n",
    "dataset['agent_answer'] = ''\n",
    "dataset['agents_score'] = ''\n",
    "dataset['gpt-4_answer'] = ''\n",
    "dataset['gpt-4_score'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ get openai api key ____\n",
    "# Path: C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\gpt-4-stuff\\openai_key.txt\n",
    "# open the file and read in the key\n",
    "with open(r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\gpt-4-stuff\\openai_key.txt', 'r') as f:\n",
    "    openai_api_key = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ init agent ____\n",
    "# init langchain agent with gpt-4\n",
    "from langchain import LLMChain, PromptTemplate, LLMMathChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import PythonREPL\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4',temperature=0, openai_api_key=openai_api_key)\n",
    "wolfram = WolframAlphaAPIWrapper(wolfram_alpha_appid='LXATGL-RJ6P2UWYT4')\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "# ____ init tools ____\n",
    "llm1 = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "llm_math_chain = LLMMathChain(llm=llm1, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer simple questions about math\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"python_repl\", \n",
    "        func=python_repl.run,\n",
    "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"wolfram_alpha\",\n",
    "        func=wolfram.run,\n",
    "        description=\"A tool that can answer questions about math, science, and more. Input should be a question. For example, `What is the derivative of x^2?`\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# ____ init prompt ____\n",
    "prefix = \"\"\"You are taking a test. Answer the math questions to the best of your ability. Equations are written in latex. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin! Remeber answer the math questions to the best of your ability. Equations are written in latex.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "# ____ run agent ____\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "\n",
    "intermediate_steps = []\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True, max_iterations=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ init gpt-4 ____\n",
    "import openai\n",
    "\n",
    "def ask_gpt4_student(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are taking a test. Answer the math questions to the best of your ability. Equations are written in latex.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    assistant_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return assistant_reply\n",
    "\n",
    "def ask_gpt4_grader(question, student_answer, actual_answer):\n",
    "    prompt = \"question: \" + question + '\\nstudent_answer: ' + student_answer + '\\nactual_answer: ' + actual_answer\n",
    "\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are evaluating a student's work. you are provided the question the student was asked, and the student's work and answer, as well as the actual answer to the question. You are to evaluate the student's work and determine if the student was CORRECT or INCORRECT. Start each response with either CORRECT or INCORRECT explain briefly why the student is right or wrong. Equations are written in latex. \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    assistant_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return assistant_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___ add a rety api call to script __\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MAX_RETRIES = 5\n",
    "\n",
    "def retry_on_failure(function, *args, **kwargs):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            return function(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES - 1:  # i.e., not on last attempt\n",
    "                sleep_seconds = 2 ** attempt  # exponential backoff\n",
    "                print(f\"Error: {e}. Retrying in {sleep_seconds} seconds...\")\n",
    "                time.sleep(sleep_seconds)\n",
    "            else:\n",
    "                print(f\"Error: {e}. No more retries.\")\n",
    "                raise e\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    problem = dataset.loc[i, 'problem']\n",
    "    solution = dataset.loc[i, 'solution']\n",
    "\n",
    "    try:\n",
    "        response = retry_on_failure(agent_executor, {'input': problem})\n",
    "        intermediate_steps = str(response[\"intermediate_steps\"])\n",
    "        agent_answer = str(response[\"output\"])\n",
    "        # agent_intermediate_steps = str(dataset.loc[i, 'agent_intermediate_steps'])\n",
    "        # agent_answer = str(dataset.loc[i, 'agent_answer'])\n",
    "        agent_scratchpad = str(agent_intermediate_steps + agent_answer)\n",
    "        agents_score = retry_on_failure(ask_gpt4_grader, problem, agent_scratchpad, solution)\n",
    "    except Exception as e:\n",
    "        agent_answer = 'failed to answer'\n",
    "        agents_score = 'INCORRECT'\n",
    "        print(f\"Error with agent: {e}\")\n",
    "\n",
    "    try:\n",
    "        gpt_4_answer = retry_on_failure(ask_gpt4_student, problem)\n",
    "        gpt_4_score = retry_on_failure(ask_gpt4_grader, problem, gpt_4_answer, solution)\n",
    "    except Exception as e:\n",
    "        gpt_4_answer = 'failed to answer'\n",
    "        gpt_4_score = 'INCORRECT'\n",
    "        print(f\"Error with GPT-4: {e}\")\n",
    "\n",
    "    dataset.loc[i, 'agent_intermediate_steps'] = intermediate_steps\n",
    "    dataset.loc[i, 'agent_answer'] = agent_answer\n",
    "    dataset.loc[i, 'agents_score'] = agents_score\n",
    "    dataset.loc[i, 'gpt-4_answer'] = gpt_4_answer\n",
    "    dataset.loc[i, 'gpt-4_score'] = gpt_4_score\n",
    "\n",
    "    dataset.to_csv('output/batch1_Q_89_120.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
