{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_9524\\542045771.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# ____ hitting all question in dataset ____ \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# get path to data C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\Synergistic_Computing_hf\\benchmarking\\new\\dataset\\MATH\\test\n",
    "path = r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\Synergistic_Computing_hf\\benchmarking\\new\\dataset\\MATH\\test'\n",
    "\n",
    "# get list of the sub directorys in directory\n",
    "sub_dir = os.listdir(path)\n",
    "\n",
    "# create a dataframe to store the contents of the files\n",
    "dataset = pd.DataFrame(columns=['problem', 'solution'])\n",
    "\n",
    "# read in the contents of 71 files from each sub directory and print the contents\n",
    "for i in sub_dir:\n",
    "    # get path to sub directory\n",
    "    sub_dir_path = os.path.join(path, i)\n",
    "    # get list of files in sub directory\n",
    "    files = os.listdir(sub_dir_path)\n",
    "    # get path to each file in sub directory. only read in the first 71 files\n",
    "    for j in files[:1]:\n",
    "        file_path = os.path.join(sub_dir_path, j)\n",
    "        # the contents of the file is a json object and i only want the 'problem' and 'solution' keys\n",
    "        df = pd.read_json(file_path, orient='index', typ='series', encoding='utf-8')\n",
    "        # append the contents of the file to the dataframe\n",
    "        dataset = dataset.append(df[['problem', 'solution']], ignore_index=True)\n",
    "\n",
    "# keep only first 2 rows of dataframe\n",
    "dataset = dataset[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many vertical asymptotes does the graph of $y=\\frac{2}{x^2+x-6}$ have?\n"
     ]
    }
   ],
   "source": [
    "# ____ creating a prompt for the agent to answer ____\n",
    "\n",
    "# read in this json file C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\Synergistic_Computing_hf\\benchmarking\\new\\dataset\\MATH\\test\\algebra\\1.json\n",
    "df = pd.read_json(r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\Synergistic_Computing_hf\\benchmarking\\new\\dataset\\MATH\\test\\algebra\\1.json', orient='index', typ='series', encoding='utf-8')\n",
    "\n",
    "example_problem = df['problem']\n",
    "print(example_problem)\n",
    "# # create a prompt to send to agent. the prompt should explain that the agent is taking a test and that the agent should answer the question. and note the the equations are written in latex. the prompt should also contain the problem\n",
    "# prompt = 'You are taking a test. Answer the math questions to the best of your ability. Equations are written in latex. \\n\\n' + df['problem'] + '\\n\\n'\n",
    "\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ get openai api key ____\n",
    "# Path: C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\gpt-4-stuff\\openai_key.txt\n",
    "# open the file and read in the key\n",
    "with open(r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\data-534_expo_proj\\gpt-4-stuff\\openai_key.txt', 'r') as f:\n",
    "    openai_api_key = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ init agent ____\n",
    "# init langchain agent with gpt-4\n",
    "from langchain import LLMChain, PromptTemplate, LLMMathChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import PythonREPL\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4',temperature=0, openai_api_key=openai_api_key)\n",
    "wolfram = WolframAlphaAPIWrapper(wolfram_alpha_appid='LXATGL-RJ6P2UWYT4')\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "# ____ init tools ____\n",
    "llm1 = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "llm_math_chain = LLMMathChain(llm=llm1, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer simple questions about math\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"python_repl\", \n",
    "        func=python_repl.run,\n",
    "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"wolfram_alpha\",\n",
    "        func=wolfram.run,\n",
    "        description=\"A tool that can answer questions about math, science, and more. Input should be a question. For example, `What is the derivative of x^2?`\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# ____ init prompt ____\n",
    "prefix = \"\"\"You are taking a test. Answer the math questions to the best of your ability. Equations are written in latex. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin! Remeber answer the math questions to the best of your ability. Equations are written in latex.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "# ____ run agent ____\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "\n",
    "intermediate_steps = []\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test agent is working\n",
    "response = agent_executor({'input':\"what is 1+1?\"})\n",
    "\n",
    "# how to grab the agents intermediate steps\n",
    "print(response[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ init gpt-4 ____\n",
    "import openai\n",
    "\n",
    "def ask_gpt4_student(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are taking a test. Answer the math questions to the best of your ability. Equations are written in latex.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    assistant_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return assistant_reply\n",
    "\n",
    "def ask_gpt4_grader(question, student_answer, actual_answer):\n",
    "    prompt = \"question: \" + question + '\\nstudent_answer: ' + student_answer + '\\nactual_answer: ' + actual_answer\n",
    "\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are evaluating a student's work. you are provided the question the student was asked, and the student's work and answer, as well as the actual answer to the question. You are to evaluate the student's work and determine if the student was CORRECT or INCORRECT. Start each response with either CORRECT or INCORRECT explain briefly why the student is right or wrong. Equations are written in latex. \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    assistant_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return assistant_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n"
     ]
    }
   ],
   "source": [
    "# test gpt-4 is working\n",
    "response = ask_gpt4(\"what is 1+1?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT: The student correctly found that 1+1 equals 2.\n"
     ]
    }
   ],
   "source": [
    "# test gpt-4 grader is working\n",
    "response = ask_gpt4_grader(\"what is 1+1?\", \"1+1=2\", \"2\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to 'dataset' dataframe add empty columns for agents intermediate steps and the agents answer. also add a column called gpt-4 answer.\n",
    "dataset['agent_intermediate_steps'] = ''\n",
    "dataset['agent_answer'] = ''\n",
    "dataset['agents_score'] = ''\n",
    "dataset['gpt-4_answer'] = ''\n",
    "dataset['gpt-4_score'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the vertical asymptotes of the given function. Vertical asymptotes occur when the denominator of a rational function is equal to zero.\n",
      "Action: Calculator\n",
      "Action Input: x^2 + x - 6 = 0\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "x^2 + x - 6 = 0\u001b[32;1m\u001b[1;3mAnswer: x = 2 or x = -3\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: x = 2 or x = -3\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found the values of x where the denominator is zero. These are the vertical asymptotes.\n",
      "Final Answer: 2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the probability that it will not rain tomorrow, I need to subtract the probability of rain from 1.\n",
      "Action: Calculator\n",
      "Action Input: 1 - 1/11\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "1 - 1/11\u001b[32;1m\u001b[1;3m\n",
      "Answer: 0.9090909090909091\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0.9090909090909091\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to convert the decimal to a common fraction.\n",
      "Action: wolfram_alpha\n",
      "Action Input: convert 0.9090909090909091 to a fraction\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mAssumption: rationalize | 0.9090909090909091 \n",
      "Answer: 10/11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: $\\frac{10}{11}$\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ____ run agent on dataset ____\n",
    "for i in range(len(dataset)):\n",
    "    # get problem from dataset\n",
    "    problem = dataset['problem'][i]\n",
    "    # get solution from dataset\n",
    "    solution = dataset['solution'][i]\n",
    "    # get the agents response\n",
    "    response = agent_executor({'input':problem})\n",
    "    # get the agents intermediate steps\n",
    "    intermediate_steps = response[\"intermediate_steps\"]\n",
    "    # get the agents answer\n",
    "    agent_answer = response[\"output\"]\n",
    "    # format agent answer and work for grading\n",
    "    agent_intermediate_steps = str(dataset['agent_intermediate_steps'][i])\n",
    "    agent_answer = str(dataset['agent_answer'][i])\n",
    "    agent_scratchpad = agent_intermediate_steps + agent_answer\n",
    "    # grade the agents answer\n",
    "    agents_score = ask_gpt4_grader(problem, agent_scratchpad, solution)\n",
    "    # get the gpt-4 answer\n",
    "    gpt_4_answer = ask_gpt4_student(problem)\n",
    "    # grade the gpt-4 answer\n",
    "    gpt_4_score = ask_gpt4_grader(problem, gpt_4_answer, solution)\n",
    "    # add the agents intermediate steps to the dataset\n",
    "    dataset['agent_intermediate_steps'][i] = intermediate_steps\n",
    "    # add the agents answer to the dataset\n",
    "    dataset['agent_answer'][i] = agent_answer\n",
    "    # add the gpt-4 answer to the dataset\n",
    "    dataset['gpt-4_answer'][i] = gpt_4_answer\n",
    "    # add the agents score to the dataset\n",
    "    dataset['agents_score'][i] = agents_score\n",
    "    # add the gpt-4 score to the dataset\n",
    "    dataset['gpt-4_score'][i] = gpt_4_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____ save dataset ____\n",
    "# save dataset to cwd\n",
    "dataset.to_csv('dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
